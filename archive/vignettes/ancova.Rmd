---
title: "ANOVA and ANCOVA Boundaries"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{ancova}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(rmarkdown.html_vignette.check_title = FALSE)
```

```{r setup}
library(RCTCovarAdjust)
library(magrittr)
```

## Data Generating Process

To use the boundary functions, including `get.boundaries` and `get.boundaries.aspend`, we need to define both a data generating process
under the null hypothesis and a test statistic function. The test statistic function
may be *different* across stages, e.g. if ANOVA is performed at each stage until the
last stage when ANCOVA is performed.

Here we create a general data generating function that simulates two-arm trial
data according to:

$$
y_i = \beta_0 + t_i \Delta + z_i \gamma + \epsilon_i
$$

$$
t_i \sim Bernoulli(0.5), \quad z_i \sim Normal(0, \theta), \quad \epsilon_i \sim Normal(0, \sigma^2)
$$
where $y_i$ is a continuous outcome, $t_i$ is the treatment effect, $z_i$ is the covariate, and $\epsilon_i$ is random error.
Note that if we set $\gamma = 0$, then there is no covariate effect.

```{r}
data.generator <- function(n, delta, gamma, theta, sigma2, b0){
  # intercept
  int <- rep(1, n)
  # covariate
  z <- rnorm(n, 0, theta)
  # treatment indicator
  t <- rbinom(n, size=1, prob=0.5) %>% ifelse(1, -1)
  # noise
  e <- rnorm(n, 0, sigma2**0.5)
  
  # outcome
  y <- int * b0 + t * delta + z * gamma + e %>% matrix
  colnames(y) <- "y"

  # design matrix
  X <- cbind(t, int, z)
  
  return(cbind(y, X))
}
```

What does one simulation look like?

```{r}
data.generator(10, delta=0, gamma=1, theta=1, sigma2=1, b0=0)
```

Now let's customize this data generating function slightly for the examples
that we'll be using by fixing some $\gamma$, $\theta$, and $\sigma^2$, and having
$\Delta = 0$ be the null value.

```{r}
null.generator <- function(n) data.generator(n=n, delta=0, gamma=1,
                                             theta=1, sigma2=1, b0=0)
```

## Test Statistic

Now we need to create functions to fit ANOVA or ANCOVA and return test statistics for each.
The idea behind the boundary functions is that as long as your data generator 
and your test statistic functions are compatible with one another, i.e. the test statistic function takes in the output of the data generator, and that the output of the data generator is a matrix, then the boundary function will work.

Below is a general function which can be used for either ANOVA or ANCOVA, since it just fits a linear regression model to estimate $\Delta$.

```{r}
fit.regression <- function(data, out.col, t.col, var.cols){
  
  # Get dimensions of problem
  n <- nrow(data)
  p <- length(var.cols) + 1 # plus one for treatment col
  
  # Get the outcome and design matrix
  # Design matrix is based on what is included in var.cols
  # If the covariate is in in var.cols, then it's ANCOVA otherwise it's ANOVA
  y <- data[, out.col]
  X <- data[, c(t.col, var.cols)]
  
  # Get the estimates
  esti <- solve(t(X) %*% X) %*% t(X) %*% y
  
  # Calculate residual variance
  residu <- y - X %*% esti
  
  # When we want to estimate the residual variance, this is what we'll do
  # but then we would need to use bounds for t-distribution
  shat <- sum(residu**2) / (n - p)
  
  # \Delta estimate
  delta <- esti[t.col-1]
  
  # Compute standardized test statistic
  tstat <- sqrt(n) * delta / sqrt(shat)
  return(tstat)
}
```

Now we will customize this function for ANOVA and ANCOVA:

```{r}
t.anova <- function(data) fit.regression(data=data, out.col=1,
                                         t.col=2, var.cols=c(3))
t.ancova <- function(data) fit.regression(data=data, out.col=1,
                                          t.col=2, var.cols=c(3, 4))
```

## Group Sequential Boundaries

At this point, we have defined the data generating mechanism,
and the test statistic functions. We can consider what the group
sequential boundaries would look like for different trial parameters.

### Constant Boundaries

One option is to consider constant boundaries on whatever scale of the test
statistic is being used. For Pocock boundaries, that is the likelihood ratio
scale, whereas for O'Brien-Fleming, that is the score statistic scale.

Note that for constant boundaries, we need to assume that the trial sequences
have an equal number of participants.

#### Pocock Boundaries

To replicate Pocock boundaries, we use the test statistic function that
we have already defined. Consider three different options: (1) perform ANOVA
at each stage, (2) perform ANCOVA at each stage, or (3) perform ANOVA at all but
the last stage. We can define sequences of test statistic functions to simulate
this process and see what boundaries preserve a fixed type I error.

```{r}
set.seed(101)

# Number of trial stages
K <- 5

# ANOVA
p.t.anova <- list()
for(i in 1:K) p.t.anova[[i]] <- t.anova

# ANCOVA
p.t.ancova <- list()
for(i in 1:K) p.t.ancova[[i]] <- t.ancova

# ANOVA-ANCOVA
p.t.mismatch <- list()
for(i in 1:(K-1)) p.t.mismatch[[i]] <- t.anova
p.t.mismatch[[K]] <- t.ancova
```

Now we will use the `get.boundaries` function with `100` people enrolled
and a type I error of `0.05`. `n_sims` controls the accuracy of the Monte Carlo
approximation to nested integration. For a 5-stage trial, the corresponding
exact Pocock boundary is `2.4132`. It is the boundary used at every stage.

```{r}
get.boundaries(power=0.05, n_sims=1000, K=K, n=100,
               stat.func=p.t.anova,
               data.generator=null.generator)
```

```{r}
get.boundaries(power=0.05, n_sims=1000, K=K, n=100,
               stat.func=p.t.ancova,
               data.generator=null.generator)
```

Now we expect that the sequence of test statistics that represent the mismatch
will result in a larger boundary than the ones with homogeneous test statistic functions
because there is less correlation between the test statistics over stages.

```{r}
get.boundaries(power=0.05, n_sims=1000, K=K, n=100,
               stat.func=p.t.mismatch,
               data.generator=null.generator)
```

#### O'Brien-Fleming Boundaries

To derive O'Brien-Fleming (OBF) boundaries, we need a test statistic
that is constant on the score statistic scale. For an equally sized stage
trial, the score statistic is equivalent to the sum of the stage-wise
test statistics, which we can derive by multiplying the cumulative stage
test-statistic by $\sqrt{k}$ where $k$ is the stage.

Therefore, to get the test statistic to use with `get.boundaries`,
we can simply modify the Pocock test statistic functions:

```{r}
# ANOVA
obf.t.anova <- mapply(FUN=function(x, y) function(z) x(z) * y, 
                      x=p.t.anova, y=sqrt(1:K))

# ANCOVA
obf.t.ancova <- mapply(FUN=function(x, y) function(z) x(z) * y, 
                       x=p.t.ancova, y=sqrt(1:K))

# ANOVA-ANCOVA
obf.t.mismatch <- mapply(FUN=function(x, y) function(z) x(z) * y, 
                         x=p.t.mismatch, y=sqrt(1:K))
```

Let's use these in the boundaries function. Note that the result that we get
are the boundaries for the test statistics on the score statistic scale.
For Pocock boundaries, the boundary that we got was constant for all stages.
For OBF boundaries, we can take the constant that we get and then divide
it by $\sqrt{k}$ to get the corresponding boundary for the $k^{th}$ stage.

We hope to get a constant value somewhere around `4.5617`.

```{r}
b.anova <- get.boundaries(power=0.05, n_sims=1000, K=K, n=100,
                          stat.func=obf.t.anova,
                          data.generator=null.generator)
b.anova
```

```{r}
b.anova / sqrt(1:K)
```

```{r}
b.ancova <- get.boundaries(power=0.05, n_sims=1000, K=K, n=100,
                           stat.func=obf.t.ancova,
                           data.generator=null.generator)
b.ancova
```

```{r}
b.ancova / sqrt(1:K)
```

Again, we expect that the sequence of test statistics that represent the mismatch
will result in a larger boundary:

```{r}
b.mismatch <- get.boundaries(power=0.05, n_sims=1000, K=K, n=100,
                             stat.func=obf.t.mismatch,
                             data.generator=null.generator)
b.mismatch
```

```{r}
b.mismatch / sqrt(1:K)
```

### Alpha-Spending

We may have a situation where we don't have equally sized stages, or want to use
up the type I error in a way that is not consistent with Pocock or OBF boundaries.
In this case, we can use $\alpha$-spending functions.

We have an equivalent function to `get.boundaries` called `get.boundaries.aspend`,
which has a few key differences. It takes the same information about a `stat.func`
and a `data.generator`, but it now needs a maximum sample size `N` and information rates
`rates` (the proportion of total sample size seen at each look). Additionally,
we need to specify both a type I error (`a`) and a function to *spend* that type I error,
`a.func`, over each of the stages.

The `a.func` or $\alpha^*$ must be monotonically increasing function, with $\alpha^*(0) = 0$
and $\alpha^*(1) = \alpha$.

#### Approximation to Pocock Boundaries

The $\alpha$-spending function that is an approximation to Pocock boundaries
is
$$
\alpha^*(t) = \alpha \log(1 + t(\exp(1) - 1))
$$

Let's define this function and see if we get something around `2.4132`.

```{r}
# the alpha-spending function
a.func.pocock <- function(a, t) a * log(1 + (exp(1) - 1) * t)

# observed information rates
t <- 1:5/5

# ANOVA
get.boundaries.aspend(a.func=a.func.pocock, a=0.05,
                      rates=t, N=1000, n_sims=1000,
                      stat.func=p.t.anova,
                      data.generator=null.generator)

# ANCOVA
get.boundaries.aspend(a.func=a.func.pocock, a=0.05,
                      rates=t, N=1000, n_sims=1000,
                      stat.func=p.t.ancova,
                      data.generator=null.generator)

# mismatch ANOVA-ANCOVA
get.boundaries.aspend(a.func=a.func.pocock, a=0.05,
                      rates=t, N=1000, n_sims=1000,
                      stat.func=p.t.mismatch,
                      data.generator=null.generator)
```

The $\alpha$-spending function that approximates OBF boundaries in a two-sided
trial is
$$
\alpha^*(t) = 4(1 - \Phi(\Phi^{-1}(1 - \alpha/4)/\sqrt{t}))
$$

where $\Phi$ is the standard normal CDF. Note that when using the
`get.boundaries.aspend` function, we would not transform the test statistic
to be on the score statistic scale now because the $\alpha$-spending function
is taking that into account in how it is defined.

```{r}
# the alpha-spending function
a.func.obf <- function(a, t) 4 * (1 - pnorm(qnorm(1-a/4)/sqrt(t)))

# observed information rates
t <- 1:5/5

# ANOVA
get.boundaries.aspend(a.func=a.func.obf, a=0.05,
                      rates=t, N=1000, n_sims=1000,
                      stat.func=p.t.anova,
                      data.generator=null.generator)

# ANCOVA
get.boundaries.aspend(a.func=a.func.obf, a=0.05,
                      rates=t, N=1000, n_sims=1000,
                      stat.func=p.t.ancova,
                      data.generator=null.generator)

# mismatch ANOVA-ANCOVA
get.boundaries.aspend(a.func=a.func.obf, a=0.05,
                      rates=t, N=1000, n_sims=1000,
                      stat.func=p.t.mismatch,
                      data.generator=null.generator)
```
